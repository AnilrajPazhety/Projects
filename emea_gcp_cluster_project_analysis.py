# -*- coding: utf-8 -*-
"""EMEA_GCP Cluster Project - Analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zv9rHK8hACHMWgRzXkh-kogVm_iH3DaS

# **Import Statements**

You must run the code blocks to generate the key to authorize the GDrive download
"""

#Pip installs
# %%capture 
#!pip install -U ggplot
#!pip install -U -q PyDrive

#Import required libraries

from __future__ import print_function

import io
import pandas as pd
import numpy as np
import pylab as pl
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import pyplot
from mpl_toolkits.mplot3d import Axes3D
from sklearn import cross_validation
from sklearn import preprocessing
from sklearn.cluster import KMeans
from sklearn.cross_validation import  train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.decomposition import PCA
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Imputer
from sklearn import mixture
from sklearn.mixture import GMM
from ggplot import *
from sklearn.manifold import TSNE
import seaborn as sns
import statsmodels.api as sm
import datetime
import collections

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from oauth2client.client import GoogleCredentials
from googleapiclient.http import MediaIoBaseDownload

from google.colab import auth
auth.authenticate_user()

from googleapiclient.discovery import build
drive_service = build('drive', 'v3')

# %matplotlib inline

"""# Helper Functions

### Google Drive Functions
"""

def downloader(file_id):
    request = drive_service.files().get_media(fileId=file_id)
    downloaded = io.BytesIO()
    downloader = MediaIoBaseDownload(downloaded, request)
    done = False
    while done is False:
        _, done = downloader.next_chunk()
    downloaded.seek(0)
    return downloaded

def delete_existing_file(file_name,file_list):
    for file1 in file_list:
        if file1['title'] == file_name:
            file1.Delete() 
            
def upload_to_drive(file_name,file_list,folder_id):
    uploaded = drive.CreateFile({'title': file_name, "parents": [{"kind": "drive#fileLink", "id": folder_id}]})
    uploaded.SetContentFile(file_name)
    uploaded.Upload()
    print('Uploaded %s with ID {}'.format(uploaded.get('id')) % file_name)
    
#Define a function to create charts with percentages

def percent_categorical(item, df, grouper, order_list=None) :
    # create groupby of item grouped by status
    groupbase = df.groupby(grouper)[item]
    # count the number of occurences
    groupcount = groupbase.count()    
    groupcount=groupcount.reset_index(drop=True)
    # convert to percentage by group rather than total count           
    groupper = (groupbase.value_counts(normalize=True).rename('percentage').mul(100).reset_index().sort_values(item))

    print("Order List: ",order_list)
    groupper = groupper.sort_values('GMS_Cluster_Membership')
    # create plot
    fig, ax = plt.subplots()
    fig.set_size_inches(11.7, 8.27)
    #ax.set_axis_bgcolor("white")
    sns.set_style("whitegrid")
    
    if order_list==None:
      brplt = sns.barplot(x=item,y='percentage',hue=groupper['GMS_Cluster_Membership'],data=groupper,palette='husl',ax=ax)#order= groupper[item].value_counts().index.tolist()).set_xticklabels(labels =  groupper[item].value_counts().index.tolist(),rotation=90)
      
    else:
      brplt = sns.barplot(x=item,y='percentage',hue=groupper['GMS_Cluster_Membership'],data=groupper,palette='husl',ax=ax,order=order_list).set_xticklabels(labels = order_list,rotation=90)
       
    #  brplt = sns.barplot(x=item,y='percentage',hue=groupper['GMS_Cluster_Membership'],data=groupper,palette='husl',ax=ax).set_xticklabels(labels = order_list,rotation=90)
    #  brplt = sns.barplot(x=item,y='percentage',hue=groupper['GMS_Cluster_Membership'],data=groupper,palette='husl',ax=ax,order=order_list).set_xticklabels(ax.get_xticklabels(),rotation=90)
       
    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
     #show plot
    return fig, ax, brplt

##Change the cluster names to A,B,C,D,E

def update_cm(x):
    if x==0:
        return 'A'
    elif x==1:
        return 'B'
    elif x==5:
        return 'C'
    elif x==6:
        return 'D'
    elif x==7:
        return 'E'
    else:
        return 'Outlier'

"""# Load DataFrames From File"""

##Update the ids to load files based on GMS-6
df_nas_id = '1gj7Zdd4_-_RXtPqNhAf_as17vY69zkMx'
df_pca_2_id = '1IRGRjGGPbwh5rMio0yQqeXUr1RVVyCVS'
df_pca_3_id = '1aVGOpNWhzj4xxStKP-qKmNVMub4rKPpR'
saved_cols_id = '1CX68W3ewGPzlpgJ_59GtV8wYa77e6dCj'
df_org_id = '1VwzDbgh4ePRzIOhBp_EwJIT8iReAca2a'

saved_cols_2_id = '1k6C4SO59qOG_u6aISkaWsLYMJ1WrsR0J'
cluster_importances_id = '1kHJmpPpN0-w3OXj35QY1FYwV0RG4veo3'
df_y_id = '1rT3q27nL3SDUA0GFvQKknFSqRHAUaAsb'

#df_copy_nas_id='1g9km1VVQ-HfXyBtviuj-_RcGQwCRhzkO'

#Load each dataframe
df_nas = pd.read_pickle(downloader(df_nas_id))
df_pca_2 = pd.read_pickle(downloader(df_pca_2_id))
df_pca_3 = pd.read_pickle(downloader(df_pca_3_id))
saved_cols = pd.read_pickle(downloader(saved_cols_id))
df_org = pd.read_pickle(downloader(df_org_id))
saved_cols_2 = pd.read_pickle(downloader(saved_cols_2_id))
cluster_importances = pd.read_pickle(downloader(cluster_importances_id))
df_y = pd.read_pickle(downloader(df_y_id))

#df_copy_nas = pd.read_pickle(downloader(df_copy_nas_id))

print("Files downloaded and dataframes ready for use.")

"""# Final Analysis of Results"""

##Creating DataFrame to compare Clusters and Respondents
cl_resp_df = saved_cols_2[['GMS_Cluster_Membership','Respondents']]

saved_cols_2['GMS_Cluster_Membership'].value_counts()

#Append cluster membership back to the df_copy_nas and saved_cols_2 dataframe and then upload the results as a CSV back to the GDrive

#Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

##Reset index of df_copy_nas

df_copy_nas=df_copy_nas.reset_index(drop=True)

#Create CSV file on CoLaboratory VM directory
final_results_df = pd.concat([saved_cols_2,df_copy_nas], axis=1, join_axes=[df_copy_nas.index])
final_results_df.shape
final_results_df.to_csv('final_cluster_results_alldata.csv', encoding='utf-8')



#Shared Data Science folder ID: 1NymTBD-2ZDvMx6MucO4ZPVJ0mCfHPmhr
fid = '1NymTBD-2ZDvMx6MucO4ZPVJ0mCfHPmhr'

file_list = drive.ListFile({'q': "'%s' in parents and trashed=false" % fid}).GetList()
            
uploaded = drive.CreateFile({'title': 'final_cluster_results_alldata.csv', "parents": [{"kind": "drive#fileLink", "id": fid}]})
#uses function created earlier in file
delete_existing_file('final_cluster_results_alldata.csv', file_list)  
uploaded.SetContentFile('final_cluster_results_alldata.csv')
uploaded.Upload()
print('Uploaded final_cluster_results_alldata.csv with ID {}'.format(uploaded.get('id')))

##ID:1RHxZCu2SmkWiOlFtcQCoJmnKomZpbTda

##Check CLuster Membership across different clusterss
#cluster_cnt = saved_cols_2[saved_cols_2['GMS_Cluster_Membership'].isin([0,2,3,4])]
arr=plt.hist(saved_cols_2['GMS_Cluster_Membership'])

for i in range(10):
    plt.text(arr[1][i],arr[0][i],str(arr[0][i]))

outliers_code = saved_cols_2[saved_cols_2['GMS_Cluster_Membership'].isin([2,3,4])].unique_code.tolist()

##Cluster Analysis- Starting with cluster 2 as it has higher chunk of respondents with 1
cl_1_df = cluster_importances[['Cluster_1','Feature_Names']]
cl_2_df = cluster_importances[['Cluster_2','Feature_Names']]
cl_3_df = cluster_importances[['Cluster_3','Feature_Names']]
cl_4_df = cluster_importances[['Cluster_4','Feature_Names']]
cl_5_df = cluster_importances[['Cluster_5','Feature_Names']]
cl_6_df = cluster_importances[['Cluster_6','Feature_Names']]
cl_7_df = cluster_importances[['Cluster_7','Feature_Names']]
cl_8_df = cluster_importances[['Cluster_8','Feature_Names']]

##Sort the df using feature_importance values to check top 10 variables
cl_1_df = cl_1_df.sort_values(by=['Cluster_1'],ascending=True)
cl_1_df.index=cl_1_df['Feature_Names'].tolist()
cl_2_df = cl_2_df.sort_values(by=['Cluster_2'],ascending=True)
cl_2_df.index=cl_2_df['Feature_Names'].tolist()
cl_3_df = cl_3_df.sort_values(by=['Cluster_3'],ascending=True)
cl_3_df.index=cl_3_df['Feature_Names'].tolist()
cl_4_df = cl_4_df.sort_values(by=['Cluster_4'],ascending=True)
cl_4_df.index=cl_4_df['Feature_Names'].tolist()
cl_5_df = cl_5_df.sort_values(by=['Cluster_5'],ascending=True)
cl_5_df.index=cl_5_df['Feature_Names'].tolist()
cl_6_df = cl_6_df.sort_values(by=['Cluster_6'],ascending=True)
cl_6_df.index=cl_6_df['Feature_Names'].tolist()

cl_7_df = cl_7_df.sort_values(by=['Cluster_7'],ascending=True)
cl_7_df.index=cl_7_df['Feature_Names'].tolist()
cl_8_df = cl_8_df.sort_values(by=['Cluster_8'],ascending=True)
cl_8_df.index=cl_8_df['Feature_Names'].tolist()

##Plot the top 20 features for Cluster 1
ax = cl_1_df['Cluster_1'].tail(15).plot(kind='barh', title ="Cluster 1", figsize=(15, 10), legend=True, fontsize=12)
ax.set_xlabel("Feature", fontsize=12)
ax.set_ylabel("Importance", fontsize=12)
plt.show()

df_nas.shape

##Sort the df using feature_importance values to check top 10 variables
cl_5_df = cl_5_df.sort_values(by=['Cluster_5'],ascending=False)

##Changing the index to feature names
cl_5_df.index=cl_5_df['Feature_Names'].tolist()

##Plot the top 20 features
ax = cl_5_df['Cluster_5'][:20].plot(kind='barh', title ="Cluster 5", figsize=(15, 10), legend=True, fontsize=12)
ax.set_xlabel("Feature", fontsize=12)
ax.set_ylabel("Importance", fontsize=12)
plt.show()

##Need to execute this code in blocks for each plot


plt.subplot(1, 4, 1)

plt_title = "Cluster A n=" + str(df_y[0].sum())
ax_1 = cl_1_df['Cluster_1'].tail(15).plot(kind='barh', title=plt_title, figsize=(4, 4), fontsize=10)
#plt.yticks(np.arange(0.00, 0.15, 0.01))
#ax_1.set_ylabel("Importance", fontsize=12)

'''
plt.subplot(1, 4, 2)

plt_title = "Cluster 2 n=" + str(df_y[1].sum())
ax_2 = cl_2_df['Cluster_2'][:20].plot(kind='bar', title =plt_title, figsize=(22, 10), fontsize=10)
plt.yticks(np.arange(0.00, 0.15, 0.01))
ax_2.set_ylabel("Importance", fontsize=12)
'''
plt.subplot(1, 4, 4)

plt_title = "Cluster B n=" + str(df_y[2].sum())
ax_3 = cl_3_df['Cluster_3'].tail(15).plot(kind='barh', title =plt_title, figsize=(4, 4), fontsize=10)
#plt.yticks(np.arange(0.00, 0.15, 0.01))
#ax_3.set_ylabel("Importance", fontsize=12)


plt.subplot(1, 5, 1)

plt_title = "Cluster C n=" + str(df_y[3].sum())
ax_4 = cl_4_df['Cluster_4'].tail(15).plot(kind='barh', title =plt_title, figsize=(4, 4), fontsize=10)
#plt.yticks(np.arange(0.00, 0.15, 0.01))
#ax_4.set_ylabel("Importance", fontsize=12)

plt.subplot(1, 5, 3)

plt_title = "Cluster D n=" + str(df_y[4].sum())
ax_5 = cl_5_df['Cluster_5'].tail(15).plot(kind='barh', title =plt_title, figsize=(4, 4), fontsize=10)
#plt.yticks(np.arange(0.00, 0.15, 0.01))
#ax_5.set_ylabel("Importance", fontsize=12)

plt.show()

"""# Comparison of Clusters with GCP Features"""

##Cluster Membership vs GCP_NA_Ratings
saved_cols_2_ratings = saved_cols_2[['GMS_Cluster_Membership','GCP_NA_Score']].pivot(columns='GMS_Cluster_Membership', index=saved_cols_2.index)
saved_cols_2_ratings.columns = saved_cols_2_ratings.columns.droplevel()
saved_cols_2_ratings.boxplot()

##Cluster Membership vs Respondents
saved_cols_2['Respondents']=saved_cols_2['Respondents'].astype(str)
saved_cols_2['GMS_Cluster_Membership']=saved_cols_2['GMS_Cluster_Membership'].astype(str)

#Cluster Membership vs GCP_NA_Score vs Respondents
#sns.lmplot("GMF_Cluster_Membership","GCP_NA_Score", data=saved_cols_2, hue='Respondents',fit_reg=False)

"""# **Personifying Clusters based on important features**"""

##Combine all the cluster information in saved_cols_2 with original dataframe df_or.

#Reset the indices for combining
df_org=df_org.reset_index(drop=True)
df_org.shape
saved_cols_2=saved_cols_2.reset_index(drop=True)
saved_cols_2.shape

saved_cols_org_df = pd.concat([saved_cols_2, df_org], axis=1, join_axes=[saved_cols_2.index])

list(saved_cols_2)

##Removing cluster 4 (index 3) only as the outlier cluster
saved_cols_org_df = saved_cols_org_df[saved_cols_org_df['GMS_Cluster_Membership'].isin(['0','1','5','6','7'])]
saved_cols_org_df.shape

saved_cols_org_df['GMS_Cluster_Membership'].value_counts()
#saved_cols_2['GMS_Cluster_Membership'].value_counts()

#Change the names of the columns to A,B,C,D
saved_cols_org_df['GMS_Cluster_Membership'] = saved_cols_org_df['GMS_Cluster_Membership'].apply(lambda x:update_cm(int(x)))
saved_cols_org_df['GMS_Cluster_Membership'].head(20)

##Respondents vs Clusters - Percentages

cl_tab  = pd.crosstab(saved_cols_org_df.GMS_Cluster_Membership,saved_cols_org_df.Respondents)
#cl_tab.plot.bar() 


cl_tab_per= cl_tab.apply(lambda r: (r/r.sum())*100, axis=1)

#cl_tab_df= cl_tab_per.stack().reset_index().rename(columns={0:'count'})

# Get current size
fig = plt.figure()
fig_size = plt.rcParams["figure.figsize"]
fig_size[0] = 12
fig_size[1] = 9
plt.rcParams["figure.figsize"] = fig_size

cl_tab_per.plot.bar() 
plt.ylabel('Percentage')

##Cluster Membership vs GCP_NA_Score
#ggplot(saved_cols_2, aes('GMS_Cluster_Membership', 'GCP_NA_Score')) + geom_violin() + geom_jitter(alpha=0.1)
sns.set_style("whitegrid")

sns.violinplot(x="GMS_Cluster_Membership", y="GCP_NA_Score", data=saved_cols_org_df,order = ['A','B','C','D','E'])

##Cluster Membership vs GCP_EMEA_Score
#ggplot(saved_cols_2, aes('GMS_Cluster_Membership', 'GCP_EMEA_Score')) + geom_violin() + geom_jitter(alpha=0.1)

sns.violinplot(x="GMS_Cluster_Membership", y="GCP_EMEA_Score", data=saved_cols_org_df,order = ['A','B','C','D','E'])
sns.set_style("whitegrid")

##Cluster Membership vs GCP_APAC_Score
#ggplot(saved_cols_2, aes('GMS_Cluster_Membership', 'GCP_APAC_Score')) + geom_violin() + geom_jitter(alpha=0.1)

sns.violinplot(x="GMS_Cluster_Membership", y="GCP_APAC_Score", data=saved_cols_org_df,order = ['A','B','C','D','E'])
sns.set_style("whitegrid")

##Cluster Membership vs GCP_NA_Rating

order_list = ['A','B','C']
fig, ax, brplt = percent_categorical('GCP_NA_Rating', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)
sns.set_style("whitegrid")

##Cross tabulate between cluster memberships and respondents to identify clusters with higher percentage of Respondent (1)
cl_tab  = pd.crosstab(saved_cols_org_df.GMS_Cluster_Membership,saved_cols_org_df.Respondents)
cl_tab.plot.bar()

#Cluster Membership vs Monthly Spend Total
order_list = ['A) $500,000+','B) $100,000+','C) $50,000+','D) $20,000+','E) $5,000+','F) $1,000+','G) < $1,000']
fig, ax, brplt = percent_categorical('Monthly Spend Total', df=saved_cols_org_df, grouper='GMS_Cluster_Membership', order_list=order_list)

saved_cols_org_df['Monthly Spend Total'].value_counts()


##Cluster B represents companies with Monthly Spend Total of < $500000+ (around 85%)

order_list=['1-10','11-50','51-100','101-200','201-500','501-1000','1001-2500','2501-5000','5001-10,000','>10,000']
fig, ax, brplt = percent_categorical('Employee Range', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

saved_cols_org_df['Employee Range'].value_counts()

##Cluster A represents companies with employee range of 11-50 (50%)

#Cluster Membership vs Data Encyrption
order_list=['Normal','Moderate','Medium']
fig, ax, brplt = percent_categorical('Data Encryption', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

##Data Encryption is high in all 4 clusters

#Cluster Membership vs Data Security
fig, ax, brplt = percent_categorical('Data Security', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

####Data Security is high in all 4 clusters

#Cluster Membership vs Data Theft
fig, ax, brplt = percent_categorical('Data Theft', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

####Data Theft is high in all 4 clusters

#Cluster Membership vs API Management
fig, ax, brplt = percent_categorical('API Management', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

#Cluster Membership vs Has Azure

order_list=['No','Yes']
fig, ax, brplt = percent_categorical('Has Azure', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

##20% of the companies which have azure as 'yes' are in cluster 3

#Cluster Membership vs G Suite

order_list=['No','Yes']
fig, ax, brplt = percent_categorical('G Suite', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

#Cluster Membership vs Security Monitoring


fig, ax, brplt = percent_categorical('Security Monitoring', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Security Monthly Spend

order_list = ['A) $500,000+','B) $100,000+','C) $50,000+','D) $20,000+','E) $5,000+','F) $1,000+','G) < $1,000']
fig, ax, brplt = percent_categorical('Security Monthly Spend', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

#Cluster Membership vs Application Count

def bin_count(x):
  
  if x ==0 :
    return '0'
  elif (x>0 and x < 5) :
    return '1-5'
  
  elif (x>5 and x <= 10) :
    return '6-10'
  
  elif (x >10 and x<=25):
    return '10-25'
  
  elif (x >25 and x<50):
    return '26-50'
  
  elif (x >50 and x<=100):
    return '51-100'
  
  elif (x >100 and x<=200):
    return '101-200'
  
  elif (x >201 and x<=5000):
    return '200-5000'
  
  elif (x >5000  and x<=8000):
    return '5000-8000'
  
  elif (x >8000  and x<=12000):
    return '8000-12000'
  
  elif (x >12000  and x<=15000):
    return '12000-15000'
  
  elif (x >15000  and x<=20000):
    return '15000-20000'
  
  elif (x >20000  and x<=25000):
    return '20000-25000'
  
  elif (x >25000  and x<=30000):
    return '25000-30000'
  
  elif (x >35000  and x<=50000):
    return '35000-50000'
  
  else:
    return '>50000'

saved_cols_org_df['App_Count_bin']=saved_cols_org_df['Application Count'].apply(lambda x:bin_count(x))
  
saved_cols_org_df['App_Count_bin'].value_counts()    
order_list=['0','1-5','6-10','10-25','26-50','51-100','101-200','200-5000','>50000']
                                                                                    
fig, ax, brplt = percent_categorical('App_Count_bin', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

##Cluster Membership vs Hybrid IT

fig, ax, brplt = percent_categorical('Hybrid IT', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Hybrid IT is high for all clusters

##Cluster Membership vs Cloud Storage

fig, ax, brplt = percent_categorical('Cloud Storage', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cloud Storage is high for all clusters

##Cluster Membership vs Social Media Count

def soc_bin(x):
  
  if x ==0 :
    return '0'
  elif (x >1 and x<10):
    return '1-10'
  elif (x >10 and x<20):
    return '10-20'
  elif (x >20 and x<50):
    return '20-50'
  elif (x >50 and x<100):
    return '50-100'
  else:
    return '>100'
  
saved_cols_org_df['Soc_Plat_Count'] =saved_cols_org_df['Social Platform Count'].apply(lambda x : soc_bin(x))

fig, ax, brplt = percent_categorical('Soc_Plat_Count', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Similar distribution across all clusters

##Cluster Membership vs Social Follower Count

def foll_bin(x):
  
  if x ==0 :
    return '0'
  elif (x >1 and x<100):
    return '1-100'
  elif (x >100 and x<500):
    return '100-500'
  elif (x >500 and x<1000):
    return '500-1000'
  elif (x >1000 and x<5000):
    return '1000-5000'
  elif (x >5000 and x<10000):
    return '5000-10000'
  
  elif (x >10000 and x<50000):
    return '10000-50000'
  elif (x >50000 and x<100000):
    return '50000-100000'
  elif (x >100000 and x<1000000):
    return '100000-500000'
     
  
  elif (x >1000000 and x<5000000):
    return '1M-5M'
  elif (x >5000000 and x<100000000):
    return '5M-10M'
  elif (x >100000000 and x<200000000):
    return '10M-20M'
  elif (x >200000000 and x<300000000):
    return '20M-30M'
  else:
    return '>30M'
  
saved_cols_org_df['Soc_foll_Count'] =saved_cols_org_df['Social Follower Count'].apply(lambda x : foll_bin(x))

order_list= ['0','1-100','100-500','500-1000','1000-5000','5000-10000','10000-50000','50000-100000','100000-500000','1M-5M','5M-10M','10M-20M','20M-30M','>30M']

fig, ax, brplt = percent_categorical('Soc_foll_Count', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

saved_cols_org_df['Soc_foll_Count'].value_counts()

##Cluster Membership vs Customer Count

def customer_count(x):
  
  if x < 10 :
    return '0-10'
  elif (x >10 and x<100):
    return '10-100'
  elif (x >100 and x<500):
    return '100-500'
  elif (x >500 and x<1000):
    return '500-1000'
  elif (x >1000 and x<10000):
    return '1000-10000'

  else:
    return '>10000'
  
saved_cols_org_df['Cust_count'] =saved_cols_org_df['Customer Count'].apply(lambda x : customer_count(x))

fig, ax, brplt = percent_categorical('Cust_count', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Similar distribution across all clusters

##Cluster Membership vs Top Alexa Rank
def alex_rank(x):
  
  if x < 100 :
    return '0-100'
  elif (x >100 and x<1000):
    return '100-1000'
  elif (x >1000 and x<10000):
    return '1000-10000'
  elif (x >10000 and x<100000):
    return '10000-100000'
  elif (x >100000 and x<1000000):
    return '100K-1M'
  elif (x >1000000 and x<10000000):
    return '1M-10M'
  elif (x >10000000 and x<20000000):
    return '10M-20M'
  elif (x >20000000 and x<30000000):
    return '20M-30M'

  else:
    return '>30M'
  
  
saved_cols_org_df['top_alexa_rank'] =saved_cols_org_df['Top Alexa Rank'].apply(lambda x : alex_rank(x))

order_list= ['0-100','100-1000','1000-10000','10000-100000','100K-1M','1M-10M','10M-20M','20M-30M','>30M']

fig, ax, brplt = percent_categorical('top_alexa_rank', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

##Similar distribution across all clusters

##Cluster 2 has a higher percentage of 10M-20M range

##Cluster Membership vs Linked Followers
def link_foll(x):
  
  if x < 100 :
    return '0-100'
  elif (x >100 and x<1000):
    return '100-1000'
  elif (x >1000 and x<10000):
    return '1000-10000'
  elif (x >10000 and x<50000):
    return '10000-50000'
  elif (x >50000 and x<100000):
    return '50000-100000'
  elif (x >100000 and x<1000000):
    return '100K-1M'
  elif (x >10000000 and x<20000000):
    return '1M-2M'

  else:
    return '>2M'
  
saved_cols_org_df['Linked_foll_count'] =saved_cols_org_df['LinkedIn Followers'].apply(lambda x : link_foll(x))

order_list=  ['0-100','100-1000','1000-10000','10000-50000','50000-100000','100K-1M','1M-2M','>2M']

fig, ax, brplt = percent_categorical('Linked_foll_count', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

##Cluster 2 has a higher percentage of linkedin follower in 100K-1M category

##Cluster 3 has a higher proportion in >2M category

saved_cols_org_df['Linked_foll_count'].value_counts()

#Cluster Membership vs NA traffic
def traf_bins(x):
  
  if x < 10 :
    return '1-10'
  elif (x >10 and x<20):
    return '10-20'
  elif (x >20 and x<30):
    return '20-30'
  elif (x >30 and x<40):
    return '30-40'
  elif (x >40 and x<50):
    return '40-50'
  elif (x >50 and x<60):
    return '50-60'
  elif (x >60 and x<70):
    return '60-70'
  elif (x >70 and x<80):
    return '50-60'
  elif (x >70 and x<80):
    return '70-80'
  elif (x >80 and x<90):
    return '80-90'
  else:
    return '>90'
  
order_list=['1-10','10-20', '20-30', '30-40', '40-50','50-60','60-70','50-60', '70-80','80-90','>90']
  
saved_cols_org_df['na_traffic_count'] =saved_cols_org_df['NA Traffic'].apply(lambda x : traf_bins(x))
fig, ax, brplt = percent_categorical('na_traffic_count', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

##Cluster Membership vs EU traffic

saved_cols_org_df['eu_traffic_count'] =saved_cols_org_df['EU Traffic'].apply(lambda x : traf_bins(x))

fig, ax, brplt = percent_categorical('eu_traffic_count', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)


#Majority of Cluster B falls in > 10-20 bracket

##Cluster Membership vs APAC traffic

saved_cols_org_df['apac_traffic_count'] =saved_cols_org_df['APAC Traffic'].apply(lambda x : traf_bins(x))


fig, ax, brplt = percent_categorical('apac_traffic_count', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

#Majority of Cluster 3 falls in > 10-20 bracket

##Cluster Membership vs LATAM traffic
saved_cols_org_df['latam_traffic_count'] =saved_cols_org_df['LATAM Traffic'].apply(lambda x : traf_bins(x))

fig, ax, brplt = percent_categorical('latam_traffic_count', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

#Cluster 3 has high traffic in apac,latam and eu regions

##Cluster Membership vs Monthly Spend Total
'''
def format_val(x):
  
  if x.notnull():
    return x.strip().replace(x[0:2],"")
  

saved_cols_org_df['Monthly Spend Total'] = saved_cols_org_df['Monthly Spend Total'].apply(lambda x:format_val(x))
'''

#g=sns.factorplot(x="Monthly Spend Total", col="GMF_Cluster_Membership", data=saved_cols_org_df, kind="count", size=4, aspect=.7)
#g=g.set_xticklabels(rotation=90)

##Most of the Cluster 4 records have a monthly spend total of 50000 USD

##Cluster Membership vs DNS Monthly Spend 
'''
def format_val(x):
  
  if x.notnull():
    return x.strip().replace(x[0:2],"")
  

saved_cols_org_df['Monthly Spend Total'] = saved_cols_org_df['Monthly Spend Total'].apply(lambda x:format_val(x))
'''

fig, ax, brplt = percent_categorical('DNS Monthly Spend', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Primary GTM (Traffic Management) Provider Monthly Spend
'''
def format_val(x):
  
  if x.notnull():
    return x.strip().replace(x[0:2],"")
  

saved_cols_org_df['Monthly Spend Total'] = saved_cols_org_df['Monthly Spend Total'].apply(lambda x:format_val(x))


'''
fig, ax, brplt = percent_categorical('Primary GTM (Traffic Management) Provider Monthly Spend', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##All companies in Cluster have GTM monthly spend > $100,000

##Cluster Membership vs Configuration
order_list=['None','Cloud Leader','Datacenter','Hybrid','Cloud Laggard']
fig, ax, brplt = percent_categorical('Configuration', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

##Cluster 3 is dominanted by cloud laggards

##Cluster Membership vs Sophistication

order_list=['0','Low','High']

fig, ax, brplt = percent_categorical('Sophistication', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

##Cluster 2 contains highest share for High Sophistication

##Cluster Membership vs Hybrid Applications

fig, ax, brplt = percent_categorical('Hybrid Applications', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Agile Tools

fig, ax, brplt = percent_categorical('Agile Tools', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Cloud Applications
fig, ax, brplt = percent_categorical('Cloud Applications', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Enterprise Application Security
fig, ax, brplt = percent_categorical('Enterprise Application Security', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Predictive Analytics

fig, ax, brplt = percent_categorical('Predictive Analytics', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Mobile Application Management

fig, ax, brplt = percent_categorical('Mobile Application Management', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Containers

fig, ax, brplt = percent_categorical('Containers', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Machine Learning

fig, ax, brplt = percent_categorical('Machine Learning', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Distributed Denial-of-Service (DDoS)


fig, ax, brplt = percent_categorical('Distributed Denial-of-Service (DDoS)', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Has Microsoft OneDrive

fig, ax, brplt = percent_categorical('Has Microsoft OneDrive', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Has Amazon AWS CloudFormation

fig, ax, brplt = percent_categorical('Has Amazon AWS CloudFormation', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Phishing
fig, ax, brplt = percent_categorical('Phishing', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Big Data Analytics

fig, ax, brplt = percent_categorical('Big Data Analytics', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Industry

##Extract most freq industries (>100)

#Create a empty list to store dns names
ind_lst=[]

ind_lst = saved_cols_org_df['Industry_LDC_PrimaryIndustry'].tolist()
len(ind_lst)

##Remove Nans
ind_lst = [ind_lst for ind_lst in ind_lst if str(ind_lst) != 'nan']

uni_ind= list(set(ind_lst))

len(uni_ind)


#Extract the count for each industry
ind_dict = {}
for i in uni_ind:
    ind_dict[i]= ind_lst.count(i)
    
#Filter Industries with more than 100 occurences across the data set
ind_fin=[]
for i in ind_dict:
    if ind_dict[i] > 50:
        ind_fin.append(i.strip())    

##Remove common industry types across clusters
#ind_fin.remove('Computer Software and Services')
#ind_fin.remove('Business Services')
ind_fin.remove('Manufacturing - Other')
ind_fin.remove('Manufacturing - Computer and Electronic')
ind_fin.remove('Manufacturing - Consumer')
ind_fin.remove('Construction')
##Create a dataframe with records containing most frequent industry types

saved_cols_org_df_ind =saved_cols_org_df[saved_cols_org_df['Industry_LDC_PrimaryIndustry'].isin(ind_fin)]
order_list=saved_cols_org_df_ind['Industry_LDC_PrimaryIndustry'].tolist()

order_list=list(set(order_list))



#fig, ax, brplt = percent_categorical('Industry_LDC_PrimaryIndustry', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Industry clusterwise
df=saved_cols_org_df_ind
item='Industry_LDC_PrimaryIndustry'

col=['muted','husl','BuGn','PuBu','husl']

grouper='GMS_Cluster_Membership'
c=0
col[c]
for cl in ['A','B','C','D','E']:
  #fig, ax, brplt = percent_categorical('Industry_LDC_PrimaryIndustry', df=saved_cols_org_df[saved_cols_org_df['GMS_Cluster_Membership']==cl], grouper='GMS_Cluster_Membership')
     # create groupby of item grouped by status
    df=saved_cols_org_df_ind[saved_cols_org_df_ind['GMS_Cluster_Membership']==cl]
    groupbase = df.groupby(grouper)[item]
    # count the number of occurences
    groupcount = groupbase.count()    
    groupcount=groupcount.reset_index(drop=True)
    # convert to percentage by group rather than total count           
    groupper = (groupbase.value_counts(normalize=True).rename('percentage').mul(100).reset_index().sort_values(item))

   # print("Order List: ",order_list)
    groupper = groupper.sort_values('percentage',ascending=False)
    # create plot
    fig, ax = plt.subplots()
    fig.set_size_inches(4, 3)
    #ax.set_axis_bgcolor("white")
    sns.set_style("whitegrid")
   # sns.color_palette("husl", col)
   
      #if order_list==None:
    #ax.set_xlabel('percentage')
    brplt = sns.barplot(y=item,x='percentage',hue=groupper['GMS_Cluster_Membership'],data=groupper[groupper['percentage']>3],ax=ax,palette=col[c])
    c +=1
    #.set_xticklabels(labels =  groupper[item].value_counts().index.tolist(),rotation=90)

##Cluster Membership vs Azure Data Lake
fig, ax, brplt = percent_categorical('Azure Data Lake', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Cloud Orchestration
fig, ax, brplt = percent_categorical('Cloud Orchestration', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Has IBM SmartCloud Enterprise 
fig, ax, brplt = percent_categorical('Has IBM SmartCloud Enterprise', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Has VMware vCloud
fig, ax, brplt = percent_categorical('Cloud Infrastructure', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Has VMware vCloud
fig, ax, brplt = percent_categorical('Hybrid Cloud', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Has Citrix CloudPlatform
fig, ax, brplt = percent_categorical('Has Citrix CloudPlatform', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Has Amazon SimpleDB
fig, ax, brplt = percent_categorical('Has Amazon SimpleDB', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Cloud IDE
fig, ax, brplt = percent_categorical('Cloud IDE', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##As compared to other cluster Cluster 3 has less companies with High Cloud IDE

##Cluster Membership vs Has Amazon EC2
fig, ax, brplt = percent_categorical('Amazon EC2', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs App Development

fig, ax, brplt = percent_categorical('App Development', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Has HP Thin Client Hardware
fig, ax, brplt = percent_categorical('Has HP Thin Client Hardware', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Cloud Backup / Recovery
fig, ax, brplt = percent_categorical('Cloud Backup / Recovery', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Company Age

def years_old(x):
  
     
  if (x>0 and x < 5):
    return '< 5 yrs'
  elif (x >5 and x<10):
    return '5 yrs-10 yrs'
  elif (x >10 and x<20):
    return '10 yrs-20 yrs'
  elif (x >20 and x<50):
    return '20-50 yrs'
  else:
    return '>50yrs'
  
import math
  
saved_cols_org_df['comp_age'] =saved_cols_org_df['Year Started'].apply(lambda x : 0 if math.isnan(x) else (2018-x))

#saved_cols_org_df['comp_age'] =saved_cols_org_df['comp_age'].apply(lambda x :years_old(x))

#fig, ax, brplt = percent_categorical('comp_age', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Violin plot after removing blank values

saved_cols_org_df_na = saved_cols_org_df[saved_cols_org_df['comp_age']!=0]

##Filetering out outliers

saved_cols_org_df_na=saved_cols_org_df_na[saved_cols_org_df['comp_age'] <100]

sns.violinplot(x="GMS_Cluster_Membership", y="comp_age", data=saved_cols_org_df_na,order = ['A','B','C','D'])


saved_cols_org_df_na.shape

##Cluster Membership vs Internet of Things (IoT)

fig, ax, brplt = percent_categorical('Internet of Things (IoT)', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Security Monitoring

fig, ax, brplt = percent_categorical('Security Monitoring', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Ransomware

fig, ax, brplt = percent_categorical('Ransomware', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Has Microsoft Office 2013
fig, ax, brplt = percent_categorical('Has Microsoft Office 2013', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Cloud Storage

fig, ax, brplt = percent_categorical('Cloud Storage', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Revenue Range

order_list=['0-1M','1-10M','11-50M','51-100M','101-250M','251-500M','501M-1B','1-5B','5B-10B','>10B']
fig, ax, brplt = percent_categorical('Revenue Range', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

##Cluster Membership vs opp_stage_name

#fig, ax, brplt = percent_categorical('opp_stage_name', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')


##Redefine opportunity into conversion and lost

def opp_re(x):
  
  if math.isnan(float(x)):
    return 'Others'
  
  elif x in ['1','2','3','4','5','6']:
    return 'opp'
  
  elif (x == 'Lost'):
    return 'Lost'
  
  elif (x == 'Recycle'):
    return 'Lost'
  
  else:
    return 'Others'
  

saved_cols_org_df['opp_re'] = saved_cols_org_df['opp_stage_name'].apply(lambda x:opp_re(x))
fig, ax, brplt = percent_categorical('opp_re', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

#Cluster Membership vs Cloud Spend 
def cs_bins(x):
  
  if x == 0 :
    return '0'
  elif (x >1 and x<100):
    return '1-100'
  elif (x >100 and x<500):
    return '100-500'
  elif (x >500 and x<1000):
    return '500-1000'
  elif (x >1000 and x<5000):
    return '1000-5000'
  elif (x >5000 and x<10000):
    return '5000-10,000'
  elif (x >10000 and x<50000):
    return '10,000-50,000'
 
  else:
    return '>50,000'
  
saved_cols_org_df['Cloud_Spend_Bins'] =saved_cols_org_df['Cloud Spend'].apply(lambda x : cs_bins(x))


fig, ax, brplt = percent_categorical('Cloud_Spend_Bins', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Cluster Membership vs Pipeline

def pip_bins(x):
  
  if x == 0 :
    return '0'
  elif (x >1 and x<100):
    return '1-100'
  elif (x >100 and x<500):
    return '100-500'
  elif (x >500 and x<1000):
    return '500-1000'
  elif (x >1000 and x<5000):
    return '1000-5000'
  elif (x >5000 and x<10000):
    return '5000-10,000'
  elif (x >10000 and x<50000):
    return '10,000-50,000'
 
  else:
    return '>50,000'
  
saved_cols_org_df['Pipeline_Bins'] =saved_cols_org_df['pipeline'].apply(lambda x : pip_bins(x))


fig, ax, brplt = percent_categorical('Pipeline_Bins', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

##Respondents distribution, % with existing pipeline values



saved_cols_org_df_na =saved_cols_org_df[saved_cols_org_df.pipeline.notnull()]


saved_cols_org_df_na=saved_cols_org_df_na[saved_cols_org_df_na['pipeline']<10000]

saved_cols_org_df_na['pipeline']=saved_cols_org_df_na['pipeline'].astype(float)

#saved_cols_org_df_na['pipeline'].plot(kind='hist',bins=80)

#sns.factorplot(x="pipeline", cols="GMS_Cluster_Membership",hue="Respondents", data=saved_cols_org_df_na,orient="h", size=2, aspect=3.5, palette="Set3",kind="hist", dodge=True, cut=0, bw=.2)

g = sns.FacetGrid(saved_cols_org_df_na, row="Respondents",col = "GMS_Cluster_Membership", margin_titles=True, col_order = ['A','B','C','D'])
bins = np.linspace(0, 10000, 500)

g.map(plt.hist, "pipeline")


#saved_cols_org_df_na['pipeline'].astype(float).describe()

##Clusters vs Opp stages vs Respondents

g = sns.factorplot(x="opp_stage_name", hue="Respondents", col="GMS_Cluster_Membership", data=saved_cols_org_df, kind="count", size=4, aspect=.7,col_order=['A','B','C','D'])
labels=saved_cols_org_df['opp_stage_name'].value_counts().index.tolist()

g.set_xticklabels(labels,rotation=90)

##Cluster Membership vs Product Deployment Count

def prod_bins(x):
  
  if x == 0 :
    return '0'
  elif (x >0 and x<10):
    return '1-10'
  elif (x >10 and x<50):
    return '10-50'
  elif (x >50 and x<100):
    return '50-100'
  elif (x >100 and x<200):
    return '100-200'
  elif (x >200 and x<500):
    return '200-500'
 
  else:
    return '>500'
  

  
order_list=['0','1-10','10-50','50-100','100-200','200-500','>500']
  
saved_cols_org_df['Prod_Bins'] =saved_cols_org_df['Product Deployment Count'].apply(lambda x : prod_bins(x))


fig, ax, brplt = percent_categorical('Prod_Bins', df=saved_cols_org_df, grouper='GMS_Cluster_Membership',order_list=order_list)

"""## Top Companies by Cluster"""

#g = sns.FacetGrid(saved_cols_org_df, col="GMF_Cluster_Membership")
#g = g.map(plt.hist, "pipeline")
saved_cols_org_df.head()

##Cluster Membership vs GCP_NA_Ratings
pd.options.display.float_format = '{:.1f}'.format
saved_cols_2_tmp = saved_cols_org_df
saved_cols_2_pipeline = saved_cols_2_tmp[['GMS_Cluster_Membership','pipeline']].pivot(columns='GMS_Cluster_Membership', index=saved_cols_2_tmp.index)
saved_cols_2_pipeline = saved_cols_2_pipeline[saved_cols_2_pipeline.pipeline.notnull()]
saved_cols_2_pipeline = saved_cols_2_pipeline.apply(pd.to_numeric, errors='ignore')
saved_cols_2_pipeline.columns = saved_cols_2_pipeline.columns.droplevel()
plot = saved_cols_2_pipeline.boxplot()
plot.set_ylim([-1000,140000])
#plot.show()

saved_cols_2_pipeline.describe()

df_pipeline_0 = saved_cols_org_df[(saved_cols_org_df['GMS_Cluster_Membership'] == 'A')]
df_pipeline_0 = df_pipeline_0[['Domain','pipeline']]
df_pipeline_0 = df_pipeline_0[df_pipeline_0.pipeline.notnull()]
df_pipeline_0 = df_pipeline_0.apply(pd.to_numeric, errors='ignore')
df_pipeline_0 = df_pipeline_0.sort_values(['pipeline'],ascending=False)
df_pipeline_0.head(50)

df_pipeline_0m = saved_cols_org_df[(saved_cols_org_df['GMS_Cluster_Membership'] == 'A')]
df_pipeline_0m = df_pipeline_0m[['Domain','pipeline']]
df_pipeline_0m = df_pipeline_0m[df_pipeline_0m.pipeline.notnull()]
df_pipeline_0m = df_pipeline_0m.apply(pd.to_numeric, errors='ignore')
df_pipeline_0m = df_pipeline_0m[(df_pipeline_0m['pipeline'] <= 32000)]
df_pipeline_0m = df_pipeline_0m.sort_values(['pipeline'],ascending=False)
df_pipeline_0m.head(50)

df_pipeline_1 = saved_cols_org_df[(saved_cols_org_df['GMS_Cluster_Membership'] == 'D')]
df_pipeline_1 = df_pipeline_1[['Domain','pipeline']]
df_pipeline_1 = df_pipeline_1[df_pipeline_1.pipeline.notnull()]
df_pipeline_1 = df_pipeline_1.apply(pd.to_numeric, errors='ignore')
df_pipeline_1 = df_pipeline_1.sort_values(['pipeline'],ascending=False)
df_pipeline_1.head(50)

df_pipeline_1m = saved_cols_org_df[(saved_cols_org_df['GMS_Cluster_Membership'] == 'D')]
df_pipeline_1m = df_pipeline_1m[['Domain','pipeline']]
df_pipeline_1m = df_pipeline_1m[df_pipeline_1m.pipeline.notnull()]
df_pipeline_1m = df_pipeline_1m.apply(pd.to_numeric, errors='ignore')
df_pipeline_1m = df_pipeline_1m[(df_pipeline_1m['pipeline'] <= 28999)]
df_pipeline_1m = df_pipeline_1m.sort_values(['pipeline'],ascending=False)
df_pipeline_1m.head(50)

df_pipeline_2 = saved_cols_org_df[(saved_cols_org_df['GMS_Cluster_Membership'] == 'C')]
df_pipeline_2 = df_pipeline_2[['Domain','pipeline']]
df_pipeline_2 = df_pipeline_2[df_pipeline_2.pipeline.notnull()]
df_pipeline_2 = df_pipeline_2.apply(pd.to_numeric, errors='ignore')
df_pipeline_2 = df_pipeline_2.sort_values(['pipeline'],ascending=False)
df_pipeline_2.head(50)

df_pipeline_2m = saved_cols_org_df[(saved_cols_org_df['GMS_Cluster_Membership'] == 'C')]
df_pipeline_2m = df_pipeline_2m[['Domain','pipeline']]
df_pipeline_2m = df_pipeline_2m[df_pipeline_2m.pipeline.notnull()]
df_pipeline_2m = df_pipeline_2m.apply(pd.to_numeric, errors='ignore')
df_pipeline_2m = df_pipeline_2m[(df_pipeline_2m['pipeline'] <= 49999)]
df_pipeline_2m = df_pipeline_2m.sort_values(['pipeline'],ascending=False)
df_pipeline_2m.head(20)

df_pipeline_4 = saved_cols_org_df[(saved_cols_org_df['GMS_Cluster_Membership'] == 'B')]
df_pipeline_4 = df_pipeline_4[['Domain','pipeline']]
df_pipeline_4 = df_pipeline_4[df_pipeline_4.pipeline.notnull()]
df_pipeline_4 = df_pipeline_4.apply(pd.to_numeric, errors='ignore')
df_pipeline_4 = df_pipeline_4.sort_values(['pipeline'],ascending=False)
df_pipeline_4.head(20)

df_pipeline_4m = saved_cols_org_df[(saved_cols_org_df['GMS_Cluster_Membership'] == 'B')]
df_pipeline_4m = df_pipeline_4m[['Domain','pipeline']]
df_pipeline_4m = df_pipeline_4m[df_pipeline_4m.pipeline.notnull()]
df_pipeline_4m = df_pipeline_4m.apply(pd.to_numeric, errors='ignore')
df_pipeline_4m = df_pipeline_4m[(df_pipeline_4m['pipeline'] <= 24000)]
df_pipeline_4m = df_pipeline_4m.sort_values(['pipeline'],ascending=False)
df_pipeline_4m.head(20)

"""# **Exploring Further using Opportunity and Conversion info**"""

import math

saved_cols_org_df.drop('opp_label',axis=1,inplace=True)
 
#Opportunities = Respondents with Pipeline Value

#Loop through each record and flag it as Opportunity if has a pipeline value

for i in saved_cols_org_df.index.tolist():

  #if saved_cols_org_df.loc[i,'Respondents']==1:
    
  #Check if pipeline has a value
  if math.isnan(float(saved_cols_org_df.loc[i,'pipeline'])):
    saved_cols_org_df.loc[i,'opp_label'] = 'No'

  elif saved_cols_org_df.loc[i,'pipeline']=='0':
    saved_cols_org_df.loc[i,'opp_label'] = 'No'
  
  elif saved_cols_org_df.loc[i,'pipeline']==0:
    saved_cols_org_df.loc[i,'opp_label'] = 'No'

  else:
    saved_cols_org_df.loc[i,'opp_label'] = 'Yes'




saved_cols_org_df[['Respondents','pipeline','opp_label']]

#saved_cols_org_df[saved_cols_org_df['pipeline'].isnan()].opp_label

saved_cols_org_df['opp_label'].value_counts()

##Check if opportunity is a conversion based on opp stage

saved_cols_org_df.drop('conv',axis=1,inplace=True)

for i in saved_cols_org_df.index.tolist():
  
  if saved_cols_org_df.loc[i,'opp_label']=='Yes':  
     ##Ignore if it is a recycled or  lost opp
     if (saved_cols_org_df.loc[i,'opp_stage_name']=='Lost'):
         saved_cols_org_df.loc[i,'conv'] = 'No'
     elif (saved_cols_org_df.loc[i,'opp_stage_name']=='Recycle'):
         saved_cols_org_df.loc[i,'conv'] = 'No'

     ##Ignore if it is missing
     elif math.isnan(float(saved_cols_org_df.loc[i,'opp_stage_name'])):
        pass

     ##Create a new variable and assign 'No' if opp stage  <=3
     elif (int (saved_cols_org_df.loc[i,'opp_stage_name']) <=3):
        saved_cols_org_df.loc[i,'conv'] = 'WIP'

     elif (int(saved_cols_org_df.loc[i,'opp_stage_name']) >=4):
        if saved_cols_org_df.loc[i,'opp_label']=='Yes':
          saved_cols_org_df.loc[i,'conv'] = 'Yes'
     else:

        pass
  else:
     saved_cols_org_df.loc[i,'conv'] = 'No'

t=saved_cols_org_df[['opp_stage_name','opp_label','conv','Respondents','pipeline','GMS_Cluster_Membership']]

t[t['conv']=="Yes"]


t['conv'].value_counts()
t['Respondents'].value_counts()

##Filtering out pipelines values with NaNs
t1= t[t['pipeline'].notnull()]

t['conv'].value_counts()


##Checking if non respondents have a pipeline value

t2= t[['Respondents','pipeline']]

t2[t2['pipeline'].notnull()]

##Conversion vs Clusters
fig, ax, brplt = percent_categorical('conv', df=t[t['conv'].isin(['Yes','No','WIP'])], grouper='GMS_Cluster_Membership')

##Conversion pattern in opp stages = 4,5,6
order_list=['4','5','6']

fig, ax, brplt = percent_categorical('opp_stage_name', df=saved_cols_org_df[saved_cols_org_df['conv']=='Yes'], grouper='GMS_Cluster_Membership',order_list=order_list)

fig, ax, brplt = percent_categorical('opp_label', df=saved_cols_org_df, grouper='GMS_Cluster_Membership')

#Conversions vs Pipeline 

##The records with pipeline >$100000 have been filtered out as they may be outliers and produce a long tail in these charts.

temp = saved_cols_org_df[['Respondents', 'GMS_Cluster_Membership','pipeline','conv','opp_label','opp_stage_name']].query('pipeline > 0 and pipeline <100000')

temp['pipeline'] = temp['pipeline'].astype('float')

sns.violinplot(x="conv", y="pipeline", data=temp[temp['conv'].isin(['Yes','No'])])

temp['conv'].value_counts()

#Conversions vs Pipeline vs Clusters

sns.factorplot("GMS_Cluster_Membership", hue="conv", y="pipeline", data=temp[temp['conv'].isin(['Yes','No'])], kind="box",order=['A','B','C','D','E'])

#pipeline vs clusters vs conversions
data=temp[temp['conv'].isin(['Yes','No'])]


sns.factorplot("GMS_Cluster_Membership", hue="conv", y="pipeline", data=data, order=['A','B','C','D','E'])

##Opp stage vs Pipeline

sns.pointplot(x="opp_stage_name", y="pipeline", data=temp[temp['conv'].isin(['Yes','No'])])

##Opp stage vs Pipeline vs Clusters



sns.factorplot(x="opp_stage_name", y="pipeline", 
               col="GMS_Cluster_Membership", data=data, size=5, aspect=.8,kind='box',col_order=['A','B','C','D','E'])


#g = sns.PairGrid(data,
 #                x_vars=["opp_stage_name", "GMS_Cluster_Membership"],
 #                y_vars=["pipeline"],
 #                aspect=.75, size=5)
#g.map(sns.violinplot, palette="pastel")